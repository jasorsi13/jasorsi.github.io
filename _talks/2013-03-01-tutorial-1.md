---
title: "Real time Geometry Extraction and Vectorization of Objects from Point-Cloud Data (PART 2)"
collection: talks
type: ""
permalink: /talks/2013-03-01-tutorial-1
venue: "Imaging, Vision & Pattern Recognition Group (IVPR)"
date: 2020-12-12
location: "Jadavpur University, Kolkata, India"
---
Tag: Semantic Surface Segmentation, 3D Point Cloud Processing, Lidar Data, Meshing

  
Venue: [Imaging, Vision & Pattern Recognition Group (IVPR)](https://sites.google.com/site/ivprgroup/home-page-ivpr?authuser=0) <br/>
Collaboration: [Department of Electronics and Telecommunication Engineering](http://www.jaduniv.edu.in/view_department.php?deptid=84) & [Department of Computer Science and Engineering](http://www.jaduniv.edu.in/view_department.php?deptid=59), [Jadavpur University](http://www.jaduniv.edu.in/), Kolkata, India <br/>
Supervisor : Prof. [Ananda Shankar Chowdhury](https://sites.google.com/site/anandachowdhury/), Prof. [Sanjoy Kumar Saha](https://scholar.google.co.in/citations?user=MVooqJUAAAAJ&hl=en) <br/>
Timeline: July’ 17 - Dec’ 20 <br/>
 * Establishment of a pipeline for real time reconstruction of geometric objects from point cloud data. Fast surface segmentation, semantic labeling, and object grouping are the major constituting subjects of the pipeline

This is an extension of our previous work [Real time Geometry Extraction and Vectorization of Objects from Point-Cloud Data (PART 1)](https://jasorsi13.github.io/jasorsi.github.io/talks/2012-03-01-talk-1).   


Single snapshot rotating LiDAR scan  
  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/1.PNG?raw=true)" <br/>
  (a) Synthetic scene with scanned point cloud overlayed (b) Point cloud with distance color coded from blue(least) to red(highest)
  
  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/9.PNG?raw=true)" <br/>
  Process flow for the entire system, the first two stages can be made online if data is sampled from Lidar on the fly.
  
  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/3.PNG?raw=true)" <br/>
  (a) A schematic showing the formation of point cloud by Lidar and (b) the resultant point cloud
 
Normal Estimation: Surface normal is generated for each point in the mesh obtained. It is estimated from the ordered neighbors of the point. This stage can also be performed in a pipelined fashion i.e. once the neighbors v is generated for a point p its corresponding surface normal can be computed. There is no need to wait for the completion of the spin. A point forms a 3D vector when joined with its neighbor i.e. all the links in the mesh are actually vectors. For surface normal computation the direction of the vector is towards its neighbors from the point in question. A normal can be estimated for a point p if its corresponding v has |v| ≥ 2. Thus, surface normal cannot be estimated for points with a single link, though in reality that is a very rare scenario. Let the map N = {< p, n >| p ∈ P, n = {iˆp, jˆp, kˆp}} stores the surface normal of all valid points. iˆp, jˆp, kˆp are the normal components of point p. For valid points, the process of neighbor formation is described in Algorithm.

  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/5.PNG?raw=true)" <br/>
Segmentation by Surface Homogeneity: Based on the normal at a point, as computed in the previous step, we now propagate the surface label. A label map L = {< p, l >|   p ∈ P, l = 0} is used for this purpose. This label map stores the label of each point p by assigning a label l. If for any point p, its l = 0 denotes the point is yet to be labeled. The criteria of assigning the label of p to its neighbor q depends on the absolute difference of their normal components. Three thresholds I, J, K   are empirically set depending on the type of environment. Segment labeling is propagated by a depth first search approach as described in algorithm 1. Two neighboring points will have the same label provided the absolute difference of corresponding components of their normals are within component-wise threshold. Computations of normals and mesh, as discussed earlier, generate the normal map N and the mesh M respectively. Subsequently algorithm 1 uses N and M to label the whole sub-sampled point cloud in an inductive fashion. Due to sub-sampling, all points in P will not get a label. This issue is resolved by assigning the label of its nearest labeled point along the horizontal sweep. An optional post-processing may be arranged by eliminating segments with too few points. 

  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/6.PNG?raw=true)" <br/>
  (a) Synthetic scene with scanned point cloud overlayed (b) Point cloud with distance color coded from blue(least) to red(highest) (c) Mesh and normals with             subsampling factor of 5 (d) Point cloud segment surface ground truth (e) A detailed look at the mesh and normals (f) Segmented point cloud by proposed methodology
  
  Comparison of execution times (all units in milliseconds) of different competing methods
  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/7.PNG?raw=true)" <br/>
  
  Comparison of accuracy of different competing methods
  ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/8.PNG?raw=true)" <br/>
 
Conclusion 
  The present work deals with the problem of semantic surface segmentation from Lidar point cloud data. The proposed methodology has a novel fast meshing process that   generates surface mesh from the Lidar scan in an online fashion, facilitating fast computation of surface normals. Subsequently a statistical method generates         segment proposals. The proposals are described with a novel feature vector based on the distribution of surface normals. Semantic labelling is done by feeding the     feature vector as input to classifier. The performance of the proposed methodology is compared with some popular cloud segmentation methods. It is observed that the   proposed methodology is significantly faster and provides higher classification accuracy. It can be concluded that the proposed methodology can deliver acceptable     accuracy for robotic applications in real time and paves the way for further utilization of semantic surfaces towards generation of models and scene reconstruction. 



More details about the work can be found on the following publication: [Semantic Segmentation of Surface from Lidar Point Cloud](https://arxiv.org/pdf/2009.05994.pdf)

 





 

---
title: "Real time Geometry Extraction and Vectorization of Objects from Point-Cloud Data"
collection: talks
type: ""
permalink: /talks/2012-03-01-talk-1
venue: "Imaging, Vision & Pattern Recognition Group (IVPR)"
date: 2020-12-12
location: "Jadavpur University, Kolkata, India"
---
Tag: 3D Vision, Machine Vision, Robot Vision, LiDAR, Point Cloud

  
Venue: [Imaging, Vision & Pattern Recognition Group (IVPR)](https://sites.google.com/site/ivprgroup/home-page-ivpr?authuser=0) <br/>
Collaboration: [Department of Electronics and Telecommunication Engineering](http://www.jaduniv.edu.in/view_department.php?deptid=84) & [Department of Computer Science and Engineering](http://www.jaduniv.edu.in/view_department.php?deptid=59), [Jadavpur University](http://www.jaduniv.edu.in/), Kolkata, India <br/>
Supervisor : Prof. [Ananda Shankar Chowdhury](https://sites.google.com/site/anandachowdhury/), Prof. [Sanjoy Kumar Saha](https://scholar.google.co.in/citations?user=MVooqJUAAAAJ&hl=en) <br/>
Timeline: July’ 17 - Dec’ 20 <br/>
 * Establishment of a pipeline for real time reconstruction of geometric objects from point cloud data. Fast surface segmentation, semantic labeling, and object grouping are the major constituting subjects of the pipeline

Single snapshot rotating LiDAR scan  
 ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/1.PNG?raw=true)" <br/>
 (a) Synthetic scene with scanned point cloud overlayed (b) Point cloud with distance color coded from blue(least) to red(highest)
  
 ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/2a.PNG?raw=true)" <br/>
Block diagram of the entire system, the first stage can be merged with Lidar scanning by improvising the Lidar firmware

 ![alt text](https://github.com/jasorsi13/jasorsi.github.io/blob/master/paper_img/3.PNG?raw=true)" <br/>
 (a) A schematic showing the formation of point cloud by Lidar and (b) the resultant point cloud
 
The proposed methodology segments the surface from a point cloud obtained by spinning Lidars only. Spinning Lidars work on the principle of spinning a vertical array of divergent laser distance sensors and thus extracts point clouds in spherical coordinates. The point cloud consists of a set of coordinates P = {p(θ, φ, r)} where θ is the fixed vertical angle of a sensor from the plane perpendicular to the spinning axis, φ is the variable horizontal angle due to spinning of the array and r is the distance measured by the laser sensor. This form of representation is exploited by our methodology to structure the data in an ordered form, the only caveat being running it for a single spin. By varying the factor of sub-sampling of φ, the horizontal density of the point cloud can be varied. Above figure shows the operational procedure of a spinning Lidar and the resultant point cloud for an object with multiple surfaces. Please note that not every point during the sweep is considered for mesh construction as noisy points too close to each other horizontally produce erroneous normal. Sub-sampling is done to rectify this error by skipping points uniformly during the spin.







 
